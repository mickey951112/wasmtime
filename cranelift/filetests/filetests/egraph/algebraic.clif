test optimize
set opt_level=speed
set use_egraphs=true
target x86_64

function %f0(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 2
    v2 = imul v0, v1
    ; check: v5 = ishl v0, v4  ; v4 = 1
    ; check: return v5
    return v2
}

function %f1() -> i64 {
block0:
  v0 = iconst.i32 0xffff_ffff_9876_5432
  v1 = uextend.i64 v0
  return v1
  ; check: v2 = iconst.i64 0x9876_5432
  ; check: return v2  ; v2 = 0x9876_5432
}

function %unsigned_shift_right_shift_left_i8(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 5
    v2 = ushr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i8 224
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %unsigned_shift_right_shift_left_i32(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 5
    v2 = ushr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i32 0xffff_ffe0
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %unsigned_shift_right_shift_left_i64(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 5
    v2 = ushr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i64 -32
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %signed_shift_right_shift_left_i8(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 5
    v2 = sshr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i8 224
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %signed_shift_right_shift_left_i32(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 5
    v2 = sshr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i32 0xffff_ffe0
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %signed_shift_right_shift_left_i64(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 5
    v2 = sshr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i64 -32
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %signed_shift_right_shift_left_i8_mask_rhs(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 0xf5
    v2 = sshr v0, v1
    v3 = ishl v2, v1
    return v3
    ; check: v4 = iconst.i8 224
    ; check: v5 = band v0, v4
    ; check: return v5
}

function %sextend_shift_32_64_unsigned(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 32
    v2 = sextend.i64 v0
    v3 = ishl v2, v1
    v4 = ushr v3, v1
    return v4
    ; check: v7 = uextend.i64 v0
    ; check: return v7
}

function %sextend_shift_32_64_signed(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 32
    v2 = sextend.i64 v0
    v3 = ishl v2, v1
    v4 = sshr v3, v1
    return v4
    ; check: return v2
}

function %sextend_undershift_32_64_unsigned(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 31
    v2 = sextend.i64 v0
    v3 = ishl v2, v1
    v4 = ushr v3, v1
    return v4
    ; check: v5 = iconst.i64 0x0001_ffff_ffff
    ; check: v6 = band v2, v5
    ; check: return v6
}

function %sextend_undershift_32_64_signed(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 31
    v2 = sextend.i64 v0
    v3 = ishl v2, v1
    v4 = sshr v3, v1
    return v4
    ; check: return v2
}

function %sextend_shift_8_64_unsigned(i8) -> i64 {
block0(v0: i8):
    v1 = iconst.i8 56
    v2 = sextend.i64 v0
    v3 = ishl v2, v1
    v4 = ushr v3, v1
    return v4
    ; check: v7 = uextend.i64 v0
    ; check: return v7
}

function %sextend_shift_8_64_signed(i8) -> i64 {
block0(v0: i8):
    v1 = iconst.i8 56
    v2 = sextend.i64 v0
    v3 = ishl v2, v1
    v4 = sshr v3, v1
    return v4
    ; check: return v2
}

function %uextend_shift_32_64_unsigned(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 32
    v2 = uextend.i64 v0
    v3 = ishl v2, v1
    v4 = ushr v3, v1
    return v4
    ; check: return v2
}

function %uextend_shift_32_64_signed(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 32
    v2 = uextend.i64 v0
    v3 = ishl v2, v1
    v4 = sshr v3, v1
    return v4
    ; check: v5 = sextend.i64 v0
    ; check: return v5
}

function %uextend_undershift_32_64_unsigned(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 31
    v2 = uextend.i64 v0
    v3 = ishl v2, v1
    v4 = ushr v3, v1
    return v4
    ; check: return v2
}

function %uextend_undershift_32_64_signed(i32) -> i64 {
block0(v0: i32):
    v1 = iconst.i8 31
    v2 = uextend.i64 v0
    v3 = ishl v2, v1
    v4 = sshr v3, v1
    return v4
    ; check: return v2
}

function %uextend_shift_8_64_unsigned(i8) -> i64 {
block0(v0: i8):
    v1 = iconst.i8 56
    v2 = uextend.i64 v0
    v3 = ishl v2, v1
    v4 = ushr v3, v1
    return v4
    ; check: return v2
}

function %uextend_shift_8_64_signed(i8) -> i64 {
block0(v0: i8):
    v1 = iconst.i8 56
    v2 = uextend.i64 v0
    v3 = ishl v2, v1
    v4 = sshr v3, v1
    return v4
    ; check: v5 = sextend.i64 v0
    ; check: return v5
}

function %double_ineg(i32) -> i32 {
block0(v0: i32):
    v1 = ineg v0
    v2 = ineg v1
    return v2
    ; check: return v0
}

function %imul_ineg_cancel(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = ineg v0
    v3 = ineg v1
    v4 = imul v2, v3
    return v4
    ; check: v5 = imul v0, v1
    ; check: return v5
}

function %iabs_ineg(i32) -> i32 {
block0(v0: i32):
    v1 = ineg v0
    v2 = iabs v1
    return v2
    ; check: v3 = iabs v0
    ; check: return v3
}

function %iabs_iabs(i32) -> i32 {
block0(v0: i32):
    v1 = iabs v0
    v2 = iabs v1
    return v2
    ; check: return v1
}

function %isub_self(i32) -> i32 {
block0(v0: i32):
    v1 = isub v0, v0
    return v1
    ; check: v2 = iconst.i32 0
    ; check: return v2
}

function %mul_minus_one(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 0xffff_ffff ; -1
    v2 = imul v0, v1
    return v2
    ; check: v3 = ineg v0
    ; check: v4 -> v3
    ; check: return v3
}

function %mul_minus_one_commuted(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 0xffff_ffff ; -1
    v2 = imul v1, v0
    return v2
    ; check: v3 = ineg v0
    ; check: v5 -> v3
    ; check: v6 -> v3
    ; check: return v3
}

function %or_and_y_with_not_y_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = band v0, v1
    v3 = bnot v1
    v4 = bor v2, v3
    return v4
    ; check: v5 = bor v0, v3
    ; check: return v5
}

function %or_and_constant_with_not_constant_i8(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 -4
    v2 = band v0, v1
    v3 = iconst.i8 3
    v4 = bor v2, v3
    return v4
    ; check: v5 = bor v0, v3
    ; check: return v5
}

function %or_and_y_with_not_y_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = band v0, v1
    v3 = bnot v1
    v4 = bor v3, v2
    return v4
    ; check: v5 = bor v0, v3
    ; check: return v5
}

function %or_and_constant_with_not_constant_i8(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 -4
    v2 = band v0, v1
    v3 = iconst.i8 3
    v4 = bor v3, v2
    return v4
    ; check: v6 = bor v0, v3
    ; check: return v6
}

function %or_and_constant_with_any_constant_should_not_apply_rule_i8(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 -4
    v2 = band v0, v1
    ;; `v3` is not `bnot(v1)` so the rewrite should not apply.
    v3 = iconst.i8 -5
    v4 = bor v2, v3
    return v4
    ; check: return v4
}

function %or_and_y_with_not_y_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = band v0, v1
    v3 = bnot v1
    v4 = bor v2, v3
    return v4
    ; check: v5 = bor v0, v3
    ; check: return v5
}

function %or_and_constant_with_not_constant_i64(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 -4
    v2 = band v0, v1
    v3 = iconst.i64 3
    v4 = bor v2, v3
    return v4
    ; check: v5 = bor v0, v3
    ; check: return v5
}

function %or_and_y_with_not_y_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = band v0, v1
    v3 = bnot v1
    v4 = bor v3, v2
    return v4
    ; check: v5 = bor v0, v3
    ; check: return v5
}

function %or_and_constant_with_not_constant_i64(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 -4
    v2 = band v0, v1
    v3 = iconst.i64 3
    v4 = bor v3, v2
    return v4
    ; check: v6 = bor v0, v3
    ; check: return v6
}

function %or_and_constant_with_any_constant_should_not_apply_rule_i64(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 -4
    v2 = band v0, v1
    ;; `v3` is not `bnot(v1)` so the rewrite should not apply.
    v3 = iconst.i64 -5
    v4 = bor v2, v3
    return v4
    ; check: return v4
}

function %bnot1(i8) -> i8 {
block0(v1: i8):
    v2 = iconst.i8 -1
    v3 = bxor v1, v2
    return v3
}

; check: v4 = bnot v1
; check: return v4

function %bnot2(i64) -> i64 {
block0(v1: i64):
    v2 = iconst.i64 -1
    v3 = bxor v1, v2
    return v3
}

; check: v4 = bnot v1
; check: return v4

function %bnot3(i64) -> i64 {
block0(v1: i64):
    v2 = iconst.i64 -1
    v3 = bxor v2, v1
    return v3
}

; check: v5 = bnot v1
; check: return v5

function %extend_always_above_zero(i32) -> i8 {
block0(v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 0
    v4 = icmp slt v2, v3
    return v4
}

; check: v5 = iconst.i8 0
; check: return v5

function %extend_always_above_zero2(i32) -> i8 {
block0(v1: i32):
    v2 = uextend.i64 v1
    v3 = iconst.i64 0
    v4 = icmp sge v2, v3
    return v4
}

; check: v7 = iconst.i8 1
; check: return v7

function %double_uextend(i16) -> i64 {
block0(v1: i16):
    v2 = uextend.i32 v1
    v3 = uextend.i64 v2
    return v3
}

; check: v4 = uextend.i64 v1
; check: return v4

function %double_sextend(i16) -> i64 {
block0(v1: i16):
    v2 = sextend.i32 v1
    v3 = sextend.i64 v2
    return v3
}

; check: v4 = sextend.i64 v1
; check: return v4

function %double_fneg(f32) -> f32 {
block0(v1: f32):
    v2 = fneg v1
    v3 = fneg v2
    return v3
}

; check: return v1

function %fma_double_fneg(f32, f32, f32) -> f32 {
block0(v1: f32, v2: f32, v3: f32):
    v4 = fneg v1
    v5 = fneg v2
    v6 = fma v4, v5, v3
    return v6
}

; check: v7 = fma v1, v2, v3
; check: return v7

function %fmul_double_fneg(f32, f32) -> f32 {
block0(v1: f32, v2: f32):
    v3 = fneg v1
    v4 = fneg v2
    v5 = fmul v3, v4
    return v5
}

; check: v6 = fmul v1, v2
; check: return v6
