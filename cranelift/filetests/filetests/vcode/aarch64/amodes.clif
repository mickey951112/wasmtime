test compile
target aarch64

function %f0(i64, i32) -> i32 {
block0(v0: i64, v1: i32):
  v2 = uextend.i64 v1
  v3 = load_complex.i32 v0+v2
  return v3
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: ldr w0, [x0, w1, UXTW]
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %f1(i64, i32) -> i32 {
block0(v0: i64, v1: i32):
  v2 = uextend.i64 v1
  v3 = load_complex.i32 v2+v0
  return v3
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: ldr w0, [x0, w1, UXTW]
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %f1(i64, i32) -> i32 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = load_complex.i32 v0+v2
  return v3
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: ldr w0, [x0, w1, SXTW]
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret

function %f1(i64, i32) -> i32 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = load_complex.i32 v2+v0
  return v3
}

; check: stp fp, lr, [sp, #-16]!
; nextln: mov fp, sp
; nextln: ldr w0, [x0, w1, SXTW]
; nextln: mov sp, fp
; nextln: ldp fp, lr, [sp], #16
; nextln: ret
