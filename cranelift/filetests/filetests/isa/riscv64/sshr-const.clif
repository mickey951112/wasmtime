test compile precise-output
set unwind_info=false
target riscv64


function %sshr_i8_const_i8(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i8 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,56
;   srai a1,t2,56
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x38
;   srai a1, t2, 0x38
;   sraiw a0, a1, 5
;   ret

function %sshr_i8_const_i16(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i16 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,56
;   srai a1,t2,56
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x38
;   srai a1, t2, 0x38
;   sraiw a0, a1, 5
;   ret

function %sshr_i8_const_i32(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i32 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,56
;   srai a1,t2,56
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x38
;   srai a1, t2, 0x38
;   sraiw a0, a1, 5
;   ret

function %sshr_i8_const_i64(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i64 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,56
;   srai a1,t2,56
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x38
;   srai a1, t2, 0x38
;   sraiw a0, a1, 5
;   ret

function %sshr_i8_const_i128(i8) -> i8 {
block0(v0: i8):
    v1 = iconst.i64 5
    v2 = uextend.i128 v1
    v3 = sshr v0, v2
    return v3
}

; VCode:
; block0:
;   slli t2,a0,56
;   srai a1,t2,56
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x38
;   srai a1, t2, 0x38
;   sraiw a0, a1, 5
;   ret

function %sshr_i16_const_i8(i16) -> i16 {
block0(v0: i16):
    v1 = iconst.i8 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,48
;   srai a1,t2,48
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x30
;   srai a1, t2, 0x30
;   sraiw a0, a1, 5
;   ret

function %sshr_i16_const_i16(i16) -> i16 {
block0(v0: i16):
    v1 = iconst.i16 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,48
;   srai a1,t2,48
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x30
;   srai a1, t2, 0x30
;   sraiw a0, a1, 5
;   ret

function %sshr_i16_const_i32(i16) -> i16 {
block0(v0: i16):
    v1 = iconst.i32 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,48
;   srai a1,t2,48
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x30
;   srai a1, t2, 0x30
;   sraiw a0, a1, 5
;   ret

function %sshr_i16_const_i64(i16) -> i16 {
block0(v0: i16):
    v1 = iconst.i64 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   slli t2,a0,48
;   srai a1,t2,48
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x30
;   srai a1, t2, 0x30
;   sraiw a0, a1, 5
;   ret

function %sshr_i16_const_i128(i16) -> i16 {
block0(v0: i16):
    v1 = iconst.i64 5
    v2 = uextend.i128 v1
    v3 = sshr v0, v2
    return v3
}

; VCode:
; block0:
;   slli t2,a0,48
;   srai a1,t2,48
;   sraiw a0,a1,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli t2, a0, 0x30
;   srai a1, t2, 0x30
;   sraiw a0, a1, 5
;   ret

function %sshr_i32_const_i8(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i8 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   sraiw a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sraiw a0, a0, 5
;   ret

function %sshr_i32_const_i16(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i16 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   sraiw a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sraiw a0, a0, 5
;   ret

function %sshr_i32_const_i32(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i32 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   sraiw a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sraiw a0, a0, 5
;   ret

function %sshr_i32_const_i64(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i64 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   sraiw a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sraiw a0, a0, 5
;   ret

function %sshr_i32_const_i128(i32) -> i32 {
block0(v0: i32):
    v1 = iconst.i64 5
    v2 = uextend.i128 v1
    v3 = sshr v0, v2
    return v3
}

; VCode:
; block0:
;   sraiw a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   sraiw a0, a0, 5
;   ret

function %sshr_i64_const_i8(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i8 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   srai a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a0, a0, 5
;   ret

function %sshr_i64_const_i16(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i16 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   srai a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a0, a0, 5
;   ret

function %sshr_i64_const_i32(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i32 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   srai a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a0, a0, 5
;   ret

function %sshr_i64_const_i64(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   srai a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a0, a0, 5
;   ret

function %sshr_i64_const_i128(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 5
    v2 = uextend.i128 v1
    v3 = sshr v0, v2
    return v3
}

; VCode:
; block0:
;   srai a0,a0,5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   srai a0, a0, 5
;   ret

function %sshr_i128_const_i8(i128) -> i128 {
block0(v0: i128):
    v1 = iconst.i8 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   li a2,5
;   andi a3,a2,63
;   li a4,64
;   sub a5,a4,a3
;   sll a7,a1,a5
;   select_reg t4,zero,a7##condition=(a3 eq zero)
;   srl t1,a0,a3
;   or a0,t4,t1
;   li a4,64
;   sra a4,a1,a3
;   li a6,-1
;   select_reg t3,a6,zero##condition=(a1 slt zero)
;   li t0,64
;   andi t2,a2,127
;   select_reg a0,a4,a0##condition=(t2 uge t0)
;   select_reg a1,t3,a4##condition=(t2 uge t0)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi a2, zero, 5
;   andi a3, a2, 0x3f
;   addi a4, zero, 0x40
;   sub a5, a4, a3
;   sll a7, a1, a5
;   beqz a3, 0xc
;   ori t4, a7, 0
;   j 8
;   ori t4, zero, 0
;   srl t1, a0, a3
;   or a0, t4, t1
;   addi a4, zero, 0x40
;   sra a4, a1, a3
;   addi a6, zero, -1
;   bltz a1, 0xc
;   ori t3, zero, 0
;   j 8
;   ori t3, a6, 0
;   addi t0, zero, 0x40
;   andi t2, a2, 0x7f
;   bgeu t2, t0, 8
;   j 8
;   ori a0, a4, 0
;   bgeu t2, t0, 0xc
;   ori a1, a4, 0
;   j 8
;   ori a1, t3, 0
;   ret

function %sshr_i128_const_i16(i128) -> i128 {
block0(v0: i128):
    v1 = iconst.i16 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   li a2,5
;   andi a3,a2,63
;   li a4,64
;   sub a5,a4,a3
;   sll a7,a1,a5
;   select_reg t4,zero,a7##condition=(a3 eq zero)
;   srl t1,a0,a3
;   or a0,t4,t1
;   li a4,64
;   sra a4,a1,a3
;   li a6,-1
;   select_reg t3,a6,zero##condition=(a1 slt zero)
;   li t0,64
;   andi t2,a2,127
;   select_reg a0,a4,a0##condition=(t2 uge t0)
;   select_reg a1,t3,a4##condition=(t2 uge t0)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi a2, zero, 5
;   andi a3, a2, 0x3f
;   addi a4, zero, 0x40
;   sub a5, a4, a3
;   sll a7, a1, a5
;   beqz a3, 0xc
;   ori t4, a7, 0
;   j 8
;   ori t4, zero, 0
;   srl t1, a0, a3
;   or a0, t4, t1
;   addi a4, zero, 0x40
;   sra a4, a1, a3
;   addi a6, zero, -1
;   bltz a1, 0xc
;   ori t3, zero, 0
;   j 8
;   ori t3, a6, 0
;   addi t0, zero, 0x40
;   andi t2, a2, 0x7f
;   bgeu t2, t0, 8
;   j 8
;   ori a0, a4, 0
;   bgeu t2, t0, 0xc
;   ori a1, a4, 0
;   j 8
;   ori a1, t3, 0
;   ret

function %sshr_i128_const_i32(i128) -> i128 {
block0(v0: i128):
    v1 = iconst.i32 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   li a2,5
;   andi a3,a2,63
;   li a4,64
;   sub a5,a4,a3
;   sll a7,a1,a5
;   select_reg t4,zero,a7##condition=(a3 eq zero)
;   srl t1,a0,a3
;   or a0,t4,t1
;   li a4,64
;   sra a4,a1,a3
;   li a6,-1
;   select_reg t3,a6,zero##condition=(a1 slt zero)
;   li t0,64
;   andi t2,a2,127
;   select_reg a0,a4,a0##condition=(t2 uge t0)
;   select_reg a1,t3,a4##condition=(t2 uge t0)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi a2, zero, 5
;   andi a3, a2, 0x3f
;   addi a4, zero, 0x40
;   sub a5, a4, a3
;   sll a7, a1, a5
;   beqz a3, 0xc
;   ori t4, a7, 0
;   j 8
;   ori t4, zero, 0
;   srl t1, a0, a3
;   or a0, t4, t1
;   addi a4, zero, 0x40
;   sra a4, a1, a3
;   addi a6, zero, -1
;   bltz a1, 0xc
;   ori t3, zero, 0
;   j 8
;   ori t3, a6, 0
;   addi t0, zero, 0x40
;   andi t2, a2, 0x7f
;   bgeu t2, t0, 8
;   j 8
;   ori a0, a4, 0
;   bgeu t2, t0, 0xc
;   ori a1, a4, 0
;   j 8
;   ori a1, t3, 0
;   ret

function %sshr_i128_const_i64(i128) -> i128 {
block0(v0: i128):
    v1 = iconst.i64 5
    v2 = sshr v0, v1
    return v2
}

; VCode:
; block0:
;   li a2,5
;   andi a3,a2,63
;   li a4,64
;   sub a5,a4,a3
;   sll a7,a1,a5
;   select_reg t4,zero,a7##condition=(a3 eq zero)
;   srl t1,a0,a3
;   or a0,t4,t1
;   li a4,64
;   sra a4,a1,a3
;   li a6,-1
;   select_reg t3,a6,zero##condition=(a1 slt zero)
;   li t0,64
;   andi t2,a2,127
;   select_reg a0,a4,a0##condition=(t2 uge t0)
;   select_reg a1,t3,a4##condition=(t2 uge t0)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi a2, zero, 5
;   andi a3, a2, 0x3f
;   addi a4, zero, 0x40
;   sub a5, a4, a3
;   sll a7, a1, a5
;   beqz a3, 0xc
;   ori t4, a7, 0
;   j 8
;   ori t4, zero, 0
;   srl t1, a0, a3
;   or a0, t4, t1
;   addi a4, zero, 0x40
;   sra a4, a1, a3
;   addi a6, zero, -1
;   bltz a1, 0xc
;   ori t3, zero, 0
;   j 8
;   ori t3, a6, 0
;   addi t0, zero, 0x40
;   andi t2, a2, 0x7f
;   bgeu t2, t0, 8
;   j 8
;   ori a0, a4, 0
;   bgeu t2, t0, 0xc
;   ori a1, a4, 0
;   j 8
;   ori a1, t3, 0
;   ret

function %sshr_i128_const_i128(i128) -> i128 {
block0(v0: i128):
    v1 = iconst.i64 5
    v2 = uextend.i128 v1
    v3 = sshr v0, v2
    return v3
}

; VCode:
; block0:
;   li a3,5
;   li a4,0
;   andi a2,a3,63
;   li a4,64
;   sub a6,a4,a2
;   sll t3,a1,a6
;   select_reg t0,zero,t3##condition=(a2 eq zero)
;   srl t2,a0,a2
;   or a4,t0,t2
;   li a5,64
;   sra a5,a1,a2
;   li a7,-1
;   select_reg t4,a7,zero##condition=(a1 slt zero)
;   li t1,64
;   andi a1,a3,127
;   select_reg a0,a5,a4##condition=(a1 uge t1)
;   select_reg a1,t4,a5##condition=(a1 uge t1)
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi a3, zero, 5
;   mv a4, zero
;   andi a2, a3, 0x3f
;   addi a4, zero, 0x40
;   sub a6, a4, a2
;   sll t3, a1, a6
;   beqz a2, 0xc
;   ori t0, t3, 0
;   j 8
;   ori t0, zero, 0
;   srl t2, a0, a2
;   or a4, t0, t2
;   addi a5, zero, 0x40
;   sra a5, a1, a2
;   addi a7, zero, -1
;   bltz a1, 0xc
;   ori t4, zero, 0
;   j 8
;   ori t4, a7, 0
;   addi t1, zero, 0x40
;   andi a1, a3, 0x7f
;   bgeu a1, t1, 0xc
;   ori a0, a4, 0
;   j 8
;   ori a0, a5, 0
;   bgeu a1, t1, 0xc
;   ori a1, a5, 0
;   j 8
;   ori a1, t4, 0
;   ret

