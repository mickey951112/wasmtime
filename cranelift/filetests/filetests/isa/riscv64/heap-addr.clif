test compile precise-output
set unwind_info=false
target riscv64

function %dynamic_heap_check(i64 vmctx, i32) -> i64 {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    heap0 = dynamic gv0, bound gv1, offset_guard 0x1000, index_type i32

block0(v0: i64, v1: i32):
    v2 = heap_addr.i64 heap0, v1, 0, 0
    return v2
}

; block0:
;   uext.w a6,a1
;   ld a7,0(a0)
;   addi t3,a7,0
;   add a7,a0,a6
;   ugt a5,a6,t3##ty=i64
;   li t3,0
;   selectif_spectre_guard a0,t3,a7##test=a5
;   ret

function %static_heap_check(i64 vmctx, i32) -> i64 {
    gv0 = vmctx
    heap0 = static gv0, bound 0x1_0000, offset_guard 0x1000, index_type i32

block0(v0: i64, v1: i32):
    v2 = heap_addr.i64 heap0, v1, 0, 0
    return v2
}

; block0:
;   uext.w a6,a1
;   add a5,a0,a6
;   lui a3,16
;   ugt a6,a6,a3##ty=i64
;   li a7,0
;   selectif_spectre_guard a0,a7,a5##test=a6
;   ret

function %dynamic_heap_check_with_offset(i64 vmctx, i32) -> i64 {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    heap0 = dynamic gv0, bound gv1, offset_guard 0x1000, index_type i32

block0(v0: i64, v1: i32):
    v2 = heap_addr.i64 heap0, v1, 16, 8
    return v2
}

; block0:
;   uext.w t4,a1
;   li a7,24
;   add t0,t4,a7
;   ult t1,t0,t4##ty=i64
;   trap_if t1,heap_oob
;   ld t1,0(a0)
;   add t2,a0,t4
;   addi t2,t2,16
;   ugt t4,t0,t1##ty=i64
;   li t1,0
;   selectif_spectre_guard a0,t1,t2##test=t4
;   ret

function %static_heap_check_with_offset(i64 vmctx, i32) -> i64 {
    gv0 = vmctx
    heap0 = static gv0, bound 0x1_0000, offset_guard 0x1000, index_type i32

block0(v0: i64, v1: i32):
    v2 = heap_addr.i64 heap0, v1, 16, 8
    return v2
}

; block0:
;   uext.w a7,a1
;   add t3,a0,a7
;   addi t3,t3,16
;   lui a5,16
;   addi a5,a5,4072
;   ugt t4,a7,a5##ty=i64
;   li t0,0
;   selectif_spectre_guard a0,t0,t3##test=t4
;   ret

