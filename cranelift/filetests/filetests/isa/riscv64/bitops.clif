test compile precise-output
set unwind_info=false
target riscv64

function %a(i8) -> i8 {
block0(v0: i8):
    v1 = bitrev v0
    return v1
}

; block0:
;   brev8 a4,a0##tmp=a3 tmp2=a1 step=a2 ty=i8
;   mv a0,a4
;   ret

function %a(i16) -> i16 {
block0(v0: i16):
    v1 = bitrev v0
    return v1
}

; block0:
;   mv t3,a0
;   brev8 a3,t3##tmp=a0 tmp2=a1 step=a2 ty=i16
;   rev8 a5,a3##step=a7 tmp=a6
;   srli a0,a5,48
;   ret

function %a(i32) -> i32 {
block0(v0: i32):
    v1 = bitrev v0
    return v1
}

; block0:
;   mv t3,a0
;   brev8 a3,t3##tmp=a0 tmp2=a1 step=a2 ty=i32
;   rev8 a5,a3##step=a7 tmp=a6
;   srli a0,a5,32
;   ret

function %a(i64) -> i64 {
block0(v0: i64):
    v1 = bitrev v0
    return v1
}

; block0:
;   rev8 a3,a0##step=a2 tmp=a1
;   brev8 a0,a3##tmp=a4 tmp2=a5 step=a6 ty=i64
;   ret

function %a(i128) -> i128 {
block0(v0: i128):
    v1 = bitrev v0
    return v1
}

; block0:
;   rev8 a2,a0##step=a4 tmp=a3
;   brev8 t4,a2##tmp=a6 tmp2=a7 step=t3 ty=i64
;   rev8 t1,a1##step=a0 tmp=t2
;   brev8 a0,t1##tmp=a2 tmp2=a3 step=a4 ty=i64
;   mv a1,t4
;   ret

function %b(i8) -> i8 {
block0(v0: i8):
    v1 = clz v0
    return v1
}

; block0:
;   clz a3,a0##ty=i8 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %b(i16) -> i16 {
block0(v0: i16):
    v1 = clz v0
    return v1
}

; block0:
;   clz a3,a0##ty=i16 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %b(i32) -> i32 {
block0(v0: i32):
    v1 = clz v0
    return v1
}

; block0:
;   clz a3,a0##ty=i32 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %b(i64) -> i64 {
block0(v0: i64):
    v1 = clz v0
    return v1
}

; block0:
;   clz a3,a0##ty=i64 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %b(i128) -> i128 {
block0(v0: i128):
    v1 = clz v0
    return v1
}

; block0:
;   clz a4,a1##ty=i64 tmp=a2 step=a3
;   clz t3,a0##ty=i64 tmp=a6 step=a7
;   li t0,64
;   select_reg t2,t3,zero##condition=(t0 eq a4)
;   add a0,a4,t2
;   li a1,0
;   ret

function %c(i8) -> i8 {
block0(v0: i8):
    v1 = cls v0
    return v1
}

; block0:
;   sext.b a1,a0
;   not a2,a0
;   select_reg a4,a2,a0##condition=(a1 slt zero)
;   clz t3,a4##ty=i8 tmp=a6 step=a7
;   addi a0,t3,-1
;   ret

function %c(i16) -> i16 {
block0(v0: i16):
    v1 = cls v0
    return v1
}

; block0:
;   sext.h a1,a0
;   not a2,a0
;   select_reg a4,a2,a0##condition=(a1 slt zero)
;   clz t3,a4##ty=i16 tmp=a6 step=a7
;   addi a0,t3,-1
;   ret

function %c(i32) -> i32 {
block0(v0: i32):
    v1 = cls v0
    return v1
}

; block0:
;   sext.w a1,a0
;   not a2,a0
;   select_reg a4,a2,a0##condition=(a1 slt zero)
;   clz t3,a4##ty=i32 tmp=a6 step=a7
;   addi a0,t3,-1
;   ret

function %c(i64) -> i64 {
block0(v0: i64):
    v1 = cls v0
    return v1
}

; block0:
;   not a1,a0
;   select_reg a2,a1,a0##condition=(a0 slt zero)
;   clz a6,a2##ty=i64 tmp=a4 step=a5
;   addi a0,a6,-1
;   ret

function %c(i128) -> i128 {
block0(v0: i128):
    v1 = cls v0
    return v1
}

; block0:
;   not a2,a0
;   select_reg a4,a2,a0##condition=(a1 slt zero)
;   not a6,a1
;   select_reg t3,a6,a1##condition=(a1 slt zero)
;   clz t2,t3##ty=i64 tmp=t0 step=t1
;   clz a3,a4##ty=i64 tmp=a1 step=a2
;   li a5,64
;   select_reg a7,a3,zero##condition=(a5 eq t2)
;   add t4,t2,a7
;   li t1,0
;   addi a0,t4,-1
;   li a1,0
;   ret

function %d(i8) -> i8 {
block0(v0: i8):
    v1 = ctz v0
    return v1
}

; block0:
;   ctz a3,a0##ty=i8 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i16) -> i16 {
block0(v0: i16):
    v1 = ctz v0
    return v1
}

; block0:
;   ctz a3,a0##ty=i16 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i32) -> i32 {
block0(v0: i32):
    v1 = ctz v0
    return v1
}

; block0:
;   ctz a3,a0##ty=i32 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i64) -> i64 {
block0(v0: i64):
    v1 = ctz v0
    return v1
}

; block0:
;   ctz a3,a0##ty=i64 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i128) -> i128 {
block0(v0: i128):
    v1 = ctz v0
    return v1
}

; block0:
;   ctz a4,a0##ty=i64 tmp=a2 step=a3
;   ctz t3,a1##ty=i64 tmp=a6 step=a7
;   li t0,64
;   select_reg t2,t3,zero##condition=(t0 eq a4)
;   add a0,a4,t2
;   li a1,0
;   ret

function %d(i128) -> i128 {
block0(v0: i128):
    v1 = popcnt v0
    return v1
}

; block0:
;   popcnt a4,a0##ty=i64 tmp=a2 step=a3
;   popcnt t3,a1##ty=i64 tmp=a6 step=a7
;   add a0,a4,t3
;   li a1,0
;   ret

function %d(i64) -> i64 {
block0(v0: i64):
    v1 = popcnt v0
    return v1
}

; block0:
;   popcnt a3,a0##ty=i64 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i32) -> i32 {
block0(v0: i32):
    v1 = popcnt v0
    return v1
}

; block0:
;   popcnt a3,a0##ty=i32 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i16) -> i16 {
block0(v0: i16):
    v1 = popcnt v0
    return v1
}

; block0:
;   popcnt a3,a0##ty=i16 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %d(i8) -> i8 {
block0(v0: i8):
    v1 = popcnt v0
    return v1
}

; block0:
;   popcnt a3,a0##ty=i8 tmp=a2 step=a1
;   mv a0,a3
;   ret

function %bnot_i32(i32) -> i32 {
block0(v0: i32):
    v1 = bnot v0
    return v1
}

; block0:
;   not a0,a0
;   ret

function %bnot_i64(i64) -> i64 {
block0(v0: i64):
    v1 = bnot v0
    return v1
}

; block0:
;   not a0,a0
;   ret

function %bnot_i64_with_shift(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = ishl.i64 v0, v1
    v3 = bnot v2
    return v3
}

; block0:
;   slli a1,a0,3
;   not a0,a1
;   ret

function %bnot_i128(i128) -> i128 {
block0(v0: i128):
    v1 = bnot v0
    return v1
}

; block0:
;   not a0,a0
;   not a1,a1
;   ret

function %band_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = band v0, v1
    return v2
}

; block0:
;   and a0,a0,a1
;   ret

function %band_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = band v0, v1
    return v2
}

; block0:
;   and a0,a0,a1
;   ret

function %band_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = band v0, v1
    return v2
}

; block0:
;   and a0,a0,a2
;   and a1,a1,a3
;   ret

function %band_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = band v0, v1
    return v2
}

; block0:
;   andi a0,a0,3
;   ret

function %band_i64_constant2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = band v1, v0
    return v2
}

; block0:
;   andi a0,a0,3
;   ret

function %band_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = band v0, v3
    return v4
}

; block0:
;   slli a2,a1,3
;   and a0,a0,a2
;   ret

function %band_i64_constant_shift2(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = band v3, v0
    return v4
}

; block0:
;   slli a2,a1,3
;   and a0,a2,a0
;   ret

function %bor_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bor v0, v1
    return v2
}

; block0:
;   or a0,a0,a1
;   ret

function %bor_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bor v0, v1
    return v2
}

; block0:
;   or a0,a0,a1
;   ret

function %bor_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bor v0, v1
    return v2
}

; block0:
;   or a0,a0,a2
;   or a1,a1,a3
;   ret

function %bor_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bor v0, v1
    return v2
}

; block0:
;   ori a0,a0,3
;   ret

function %bor_i64_constant2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bor v1, v0
    return v2
}

; block0:
;   ori a0,a0,3
;   ret

function %bor_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bor v0, v3
    return v4
}

; block0:
;   slli a2,a1,3
;   or a0,a0,a2
;   ret

function %bor_i64_constant_shift2(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bor v3, v0
    return v4
}

; block0:
;   slli a2,a1,3
;   or a0,a2,a0
;   ret

function %bxor_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bxor v0, v1
    return v2
}

; block0:
;   xor a0,a0,a1
;   ret

function %bxor_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bxor v0, v1
    return v2
}

; block0:
;   xor a0,a0,a1
;   ret

function %bxor_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bxor v0, v1
    return v2
}

; block0:
;   xor a0,a0,a2
;   xor a1,a1,a3
;   ret

function %bxor_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bxor v0, v1
    return v2
}

; block0:
;   xori a0,a0,3
;   ret

function %bxor_i64_constant2(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 3
    v2 = bxor v1, v0
    return v2
}

; block0:
;   xori a0,a0,3
;   ret

function %bxor_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bxor v0, v3
    return v4
}

; block0:
;   slli a2,a1,3
;   xor a0,a0,a2
;   ret

function %bxor_i64_constant_shift2(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 3
    v3 = ishl.i64 v1, v2
    v4 = bxor v3, v0
    return v4
}

; block0:
;   slli a2,a1,3
;   xor a0,a2,a0
;   ret

function %band_not_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = band_not v0, v1
    return v2
}

; block0:
;   not a1,a1
;   and a0,a0,a1
;   ret

function %band_not_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = band_not v0, v1
    return v2
}

; block0:
;   not a1,a1
;   and a0,a0,a1
;   ret

function %band_not_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = band_not v0, v1
    return v2
}

; block0:
;   not a4,a2
;   and a0,a0,a4
;   not t3,a3
;   and a1,a1,t3
;   ret

function %band_not_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 4
    v2 = band_not v0, v1
    return v2
}

; block0:
;   li a1,4
;   not a2,a1
;   and a0,a0,a2
;   ret

function %band_not_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 4
    v3 = ishl.i64 v1, v2
    v4 = band_not v0, v3
    return v4
}

; block0:
;   slli a3,a1,4
;   not a2,a3
;   and a0,a0,a2
;   ret

function %bor_not_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bor_not v0, v1
    return v2
}

; block0:
;   not a1,a1
;   or a0,a0,a1
;   ret

function %bor_not_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bor_not v0, v1
    return v2
}

; block0:
;   not a1,a1
;   or a0,a0,a1
;   ret

function %bor_not_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bor_not v0, v1
    return v2
}

; block0:
;   not a4,a2
;   or a0,a0,a4
;   not t3,a3
;   or a1,a1,t3
;   ret

function %bor_not_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 4
    v2 = bor_not v0, v1
    return v2
}

; block0:
;   li a1,4
;   not a2,a1
;   or a0,a0,a2
;   ret

function %bor_not_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 4
    v3 = ishl.i64 v1, v2
    v4 = bor_not v0, v3
    return v4
}

; block0:
;   slli a3,a1,4
;   not a2,a3
;   or a0,a0,a2
;   ret

function %bxor_not_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
    v2 = bxor_not v0, v1
    return v2
}

; block0:
;   not a1,a1
;   xor a0,a0,a1
;   ret

function %bxor_not_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = bxor_not v0, v1
    return v2
}

; block0:
;   not a1,a1
;   xor a0,a0,a1
;   ret

function %bxor_not_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = bxor_not v0, v1
    return v2
}

; block0:
;   not a4,a2
;   xor a0,a0,a4
;   not t3,a3
;   xor a1,a1,t3
;   ret

function %bxor_not_i64_constant(i64) -> i64 {
block0(v0: i64):
    v1 = iconst.i64 4
    v2 = bxor_not v0, v1
    return v2
}

; block0:
;   li a1,4
;   not a2,a1
;   xor a0,a0,a2
;   ret

function %bxor_not_i64_constant_shift(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
    v2 = iconst.i64 4
    v3 = ishl.i64 v1, v2
    v4 = bxor_not v0, v3
    return v4
}

; block0:
;   slli a3,a1,4
;   not a2,a3
;   xor a0,a0,a2
;   ret

function %ishl_i128_i8(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = ishl.i128 v0, v1
    return v2
}

; block0:
;   andi a3,a2,127
;   li a5,128
;   sub a5,a5,a3
;   sll t3,a0,a3
;   srl t0,a0,a5
;   select_reg t2,zero,t0##condition=(a3 eq zero)
;   sll a1,a1,a3
;   or a4,t2,a1
;   li a5,64
;   select_reg a0,zero,t3##condition=(a3 uge a5)
;   select_reg a1,t3,a4##condition=(a3 uge a5)
;   ret

function %ishl_i128_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ishl.i128 v0, v1
    return v2
}

; block0:
;   andi a4,a2,127
;   li a6,128
;   sub a6,a6,a4
;   sll t4,a0,a4
;   srl t1,a0,a6
;   select_reg a0,zero,t1##condition=(a4 eq zero)
;   sll a2,a1,a4
;   or a5,a0,a2
;   li a6,64
;   select_reg a0,zero,t4##condition=(a4 uge a6)
;   select_reg a1,t4,a5##condition=(a4 uge a6)
;   ret

function %ushr_i128_i8(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = ushr.i128 v0, v1
    return v2
}

; block0:
;   andi a3,a2,127
;   li a5,128
;   sub a5,a5,a3
;   sll t3,a1,a5
;   select_reg t0,zero,t3##condition=(a3 eq zero)
;   srl t2,a0,a3
;   or a2,t0,t2
;   li a4,64
;   srl a5,a1,a3
;   select_reg a0,a5,a2##condition=(a3 uge a4)
;   select_reg a1,zero,a5##condition=(a3 uge a4)
;   ret

function %ushr_i128_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = ushr.i128 v0, v1
    return v2
}

; block0:
;   andi a4,a2,127
;   li a6,128
;   sub a6,a6,a4
;   sll t4,a1,a6
;   select_reg t1,zero,t4##condition=(a4 eq zero)
;   srl a0,a0,a4
;   or a2,t1,a0
;   li a5,64
;   srl a6,a1,a4
;   select_reg a0,a6,a2##condition=(a4 uge a5)
;   select_reg a1,zero,a6##condition=(a4 uge a5)
;   ret

function %sshr_i128_i8(i128, i8) -> i128 {
block0(v0: i128, v1: i8):
    v2 = sshr.i128 v0, v1
    return v2
}

; block0:
;   andi a3,a2,127
;   li a5,128
;   sub a5,a5,a3
;   sll t3,a1,a5
;   select_reg t0,zero,t3##condition=(a3 eq zero)
;   srl t2,a0,a3
;   or a2,t0,t2
;   li a4,64
;   sra a5,a1,a3
;   li a7,-1
;   select_reg t4,a7,zero##condition=(a1 slt zero)
;   select_reg a0,a5,a2##condition=(a3 uge a4)
;   select_reg a1,t4,a5##condition=(a3 uge a4)
;   ret

function %sshr_i128_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
    v2 = sshr.i128 v0, v1
    return v2
}

; block0:
;   andi a4,a2,127
;   li a6,128
;   sub a6,a6,a4
;   sll t4,a1,a6
;   select_reg t1,zero,t4##condition=(a4 eq zero)
;   srl a0,a0,a4
;   or a2,t1,a0
;   li a5,64
;   sra a6,a1,a4
;   li t3,-1
;   select_reg t0,t3,zero##condition=(a1 slt zero)
;   select_reg a0,a6,a2##condition=(a4 uge a5)
;   select_reg a1,t0,a6##condition=(a4 uge a5)
;   ret

