test compile
target aarch64

function %swidenhigh_i8x16(i8) -> i16x8 {
  gv0 = dyn_scale_target_const.i16x8
  gv1 = dyn_scale_target_const.i8x16
  dt0 = i8x16*gv1
  dt1 = i16x8*gv0

block0(v0: i8):
  v1 = splat.dt0 v0
  v2 = swiden_high v1
  v3 = extract_vector v2, 0
  return v3
}

; check: dup v2.16b, w0
; nextln: sxtl2 v0.8h, v2.16b
; nextln: ret

function %swidenhigh_i16x8(i16) -> i32x4 {
  gv0 = dyn_scale_target_const.i32x4
  gv1 = dyn_scale_target_const.i16x8
  dt0 = i16x8*gv1
  dt1 = i32x4*gv0

block0(v0: i16):
  v1 = splat.dt0 v0
  v2 = swiden_high v1
  v3 = extract_vector v2, 0
  return v3
}

; check: dup v2.8h, w0
; nextln: sxtl2 v0.4s, v2.8h
; nextln: ret

function %swidenhigh_i32x4(i32) -> i64x2 {
  gv0 = dyn_scale_target_const.i32x4
  gv1 = dyn_scale_target_const.i64x2
  dt0 = i64x2*gv1
  dt1 = i32x4*gv0

block0(v0: i32):
  v1 = splat.dt1 v0
  v2 = swiden_high v1
  v3 = extract_vector v2, 0
  return v3
}

; check: dup v2.4s, w0
; nextln: sxtl2 v0.2d, v2.4s
; nextln: ret

function %swidenlow_i8x16(i8) -> i16x8 {
  gv0 = dyn_scale_target_const.i16x8
  gv1 = dyn_scale_target_const.i8x16
  dt0 = i8x16*gv1
  dt1 = i16x8*gv0

block0(v0: i8):
  v1 = splat.dt0 v0
  v2 = swiden_low v1
  v3 = extract_vector v2, 0
  return v3
}

; check: dup v2.16b, w0
; nextln: sxtl v0.8h, v2.8b
; nextln: ret

function %swidenlow_i16x8(i16) -> i32x4 {
  gv0 = dyn_scale_target_const.i32x4
  gv1 = dyn_scale_target_const.i16x8
  dt0 = i16x8*gv1
  dt1 = i32x4*gv0

block0(v0: i16):
  v1 = splat.dt0 v0
  v2 = swiden_low v1
  v3 = extract_vector v2, 0
  return v3
}

; check: dup v2.8h, w0
; nextln: sxtl v0.4s, v2.4h
; nextln: ret

function %swidenlow_i32x4(i32) -> i64x2 {
  gv0 = dyn_scale_target_const.i32x4
  gv1 = dyn_scale_target_const.i64x2
  dt0 = i64x2*gv1
  dt1 = i32x4*gv0

block0(v0: i32):
  v1 = splat.dt1 v0
  v2 = swiden_low v1
  v3 = extract_vector v2, 0
  return v3
}

; check: dup v2.4s, w0
; nextln: sxtl v0.2d, v2.2s
; nextln: ret
