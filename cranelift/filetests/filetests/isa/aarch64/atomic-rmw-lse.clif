test compile precise-output
target aarch64 has_lse

function %atomic_rmw_add_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 add v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldaddal x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_add_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 add v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldaddal w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_and_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 and v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldclral x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_and_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 and v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldclral w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_or_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 or v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldsetal x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_or_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 or v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldsetal w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_xor_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 xor v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldeoral x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_xor_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 xor v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldeoral w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_smax_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 smax v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldsmaxal x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_smax_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 smax v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldsmaxal w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_umax_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 umax v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldumaxal x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_umax_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 umax v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldumaxal w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_smin_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 smin v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldsminal x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_smin_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 smin v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   ldsminal w1, w0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_umin_i64(i64, i64) {
block0(v0: i64, v1: i64):
    v2 = atomic_rmw.i64 umin v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   lduminal x1, x0, [x0]
;   Inst 1:   ret
; }}

function %atomic_rmw_umin_i32(i32, i32) {
block0(v0: i32, v1: i32):
    v2 = atomic_rmw.i32 umin v0, v1
    return
}

; VCode_ShowWithRRU {{
;   Entry block: 0
; Block 0:
;   (original IR block: block0)
;   (instruction range: 0 .. 2)
;   Inst 0:   lduminal w1, w0, [x0]
;   Inst 1:   ret
; }}

