test compile precise-output
target aarch64

function %f1(i8x16) -> i8 {
block0(v0: i8x16):
  v1 = vhigh_bits.i8 v0
  return v1
}

; block0:
;   sshr v2.16b, v0.16b, #7
;   movz x5, #513
;   movk x5, x5, #2052, LSL #16
;   movk x5, x5, #8208, LSL #32
;   movk x5, x5, #32832, LSL #48
;   dup v16.2d, x5
;   and v19.16b, v2.16b, v16.16b
;   ext v21.16b, v19.16b, v19.16b, #8
;   zip1 v23.16b, v19.16b, v21.16b
;   addv h25, v23.8h
;   umov w0, v25.h[0]
;   ret

function %f2(i8x16) -> i16 {
block0(v0: i8x16):
  v1 = vhigh_bits.i16 v0
  return v1
}

; block0:
;   sshr v2.16b, v0.16b, #7
;   movz x5, #513
;   movk x5, x5, #2052, LSL #16
;   movk x5, x5, #8208, LSL #32
;   movk x5, x5, #32832, LSL #48
;   dup v16.2d, x5
;   and v19.16b, v2.16b, v16.16b
;   ext v21.16b, v19.16b, v19.16b, #8
;   zip1 v23.16b, v19.16b, v21.16b
;   addv h25, v23.8h
;   umov w0, v25.h[0]
;   ret

function %f3(i16x8) -> i8 {
block0(v0: i16x8):
  v1 = vhigh_bits.i8 v0
  return v1
}

; block0:
;   sshr v2.8h, v0.8h, #15
;   ldr q4, pc+8 ; b 20 ; data.f128 0x00800040002000100008000400020001
;   and v6.16b, v2.16b, v4.16b
;   addv h16, v6.8h
;   umov w0, v16.h[0]
;   ret

function %f4(i32x4) -> i8 {
block0(v0: i32x4):
  v1 = vhigh_bits.i8 v0
  return v1
}

; block0:
;   sshr v2.4s, v0.4s, #31
;   ldr q4, pc+8 ; b 20 ; data.f128 0x00000008000000040000000200000001
;   and v6.16b, v2.16b, v4.16b
;   addv s16, v6.4s
;   mov w0, v16.s[0]
;   ret

function %f5(i64x2) -> i8 {
block0(v0: i64x2):
  v1 = vhigh_bits.i8 v0
  return v1
}

; block0:
;   mov x2, v0.d[1]
;   mov x4, v0.d[0]
;   lsr x6, x2, #63
;   lsr x8, x4, #63
;   add x0, x8, x6, LSL 1
;   ret

