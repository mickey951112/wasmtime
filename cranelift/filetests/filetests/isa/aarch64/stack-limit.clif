test compile precise-output
set unwind_info=false
target aarch64

function %foo() {
block0:
    return
}

; VCode:
; block0:
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   ret

function %stack_limit_leaf_zero(i64 stack_limit) {
block0(v0: i64):
    return
}

; VCode:
; block0:
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   ret

function %stack_limit_gv_leaf_zero(i64 vmctx) {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    gv2 = load.i64 notrap aligned gv1+4
    stack_limit = gv2
block0(v0: i64):
    return
}

; VCode:
; block0:
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   ret

function %stack_limit_call_zero(i64 stack_limit) {
    fn0 = %foo()
block0(v0: i64):
    call fn0()
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   subs xzr, sp, x0, UXTX
;   b.hs 8 ; udf
; block0:
;   load_ext_name x2, TestCase(%foo)+0
;   blr x2
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   cmp sp, x0
;   b.hs #0x14
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
; block1: ; offset 0x14
;   ldr x2, #0x1c
;   b #0x24
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %foo 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x2
;   ldp x29, x30, [sp], #0x10
;   ret

function %stack_limit_gv_call_zero(i64 vmctx) {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    gv2 = load.i64 notrap aligned gv1+4
    stack_limit = gv2
    fn0 = %foo()
block0(v0: i64):
    call fn0()
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   ldr x16, [x0]
;   ldr x16, [x16, #4]
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
; block0:
;   load_ext_name x2, TestCase(%foo)+0
;   blr x2
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   ldur x16, [x0]
;   ldur x16, [x16, #4]
;   cmp sp, x16
;   b.hs #0x1c
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
; block1: ; offset 0x1c
;   ldr x2, #0x24
;   b #0x2c
;   .byte 0x00, 0x00, 0x00, 0x00 ; reloc_external Abs8 %foo 0
;   .byte 0x00, 0x00, 0x00, 0x00
;   blr x2
;   ldp x29, x30, [sp], #0x10
;   ret

function %stack_limit(i64 stack_limit) {
    ss0 = explicit_slot 168
block0(v0: i64):
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   add x16, x0, #176
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
;   sub sp, sp, #176
; block0:
;   add sp, sp, #176
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   add x16, x0, #0xb0
;   cmp sp, x16
;   b.hs #0x18
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   sub sp, sp, #0xb0
; block1: ; offset 0x1c
;   add sp, sp, #0xb0
;   ldp x29, x30, [sp], #0x10
;   ret

function %huge_stack_limit(i64 stack_limit) {
    ss0 = explicit_slot 400000
block0(v0: i64):
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   subs xzr, sp, x0, UXTX
;   b.hs 8 ; udf
;   movz w17, #6784
;   movk w17, w17, #6, LSL #16
;   add x16, x0, x17, UXTX
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
;   movz w16, #6784
;   movk w16, w16, #6, LSL #16
;   sub sp, sp, x16, UXTX
; block0:
;   movz w16, #6784
;   movk w16, w16, #6, LSL #16
;   add sp, sp, x16, UXTX
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   cmp sp, x0
;   b.hs #0x14
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   mov w17, #0x1a80
;   movk w17, #6, lsl #16
;   add x16, x0, x17, uxtx
;   cmp sp, x16
;   b.hs #0x2c
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   mov w16, #0x1a80
;   movk w16, #6, lsl #16
;   sub sp, sp, x16
; block1: ; offset 0x38
;   mov w16, #0x1a80
;   movk w16, #6, lsl #16
;   add sp, sp, x16
;   ldp x29, x30, [sp], #0x10
;   ret

function %limit_preamble(i64 vmctx) {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    gv2 = load.i64 notrap aligned gv1+4
    stack_limit = gv2
    ss0 = explicit_slot 20
block0(v0: i64):
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   ldr x16, [x0]
;   ldr x16, [x16, #4]
;   add x16, x16, #32
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
;   sub sp, sp, #32
; block0:
;   add sp, sp, #32
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   ldur x16, [x0]
;   ldur x16, [x16, #4]
;   add x16, x16, #0x20
;   cmp sp, x16
;   b.hs #0x20
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   sub sp, sp, #0x20
; block1: ; offset 0x24
;   add sp, sp, #0x20
;   ldp x29, x30, [sp], #0x10
;   ret

function %limit_preamble_huge(i64 vmctx) {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0
    gv2 = load.i64 notrap aligned gv1+4
    stack_limit = gv2
    ss0 = explicit_slot 400000
block0(v0: i64):
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   ldr x16, [x0]
;   ldr x16, [x16, #4]
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
;   movz w17, #6784
;   movk w17, w17, #6, LSL #16
;   add x16, x16, x17, UXTX
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
;   movz w16, #6784
;   movk w16, w16, #6, LSL #16
;   sub sp, sp, x16, UXTX
; block0:
;   movz w16, #6784
;   movk w16, w16, #6, LSL #16
;   add sp, sp, x16, UXTX
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   ldur x16, [x0]
;   ldur x16, [x16, #4]
;   cmp sp, x16
;   b.hs #0x1c
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   mov w17, #0x1a80
;   movk w17, #6, lsl #16
;   add x16, x16, x17, uxtx
;   cmp sp, x16
;   b.hs #0x34
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   mov w16, #0x1a80
;   movk w16, #6, lsl #16
;   sub sp, sp, x16
; block1: ; offset 0x40
;   mov w16, #0x1a80
;   movk w16, #6, lsl #16
;   add sp, sp, x16
;   ldp x29, x30, [sp], #0x10
;   ret

function %limit_preamble_huge_offset(i64 vmctx) {
    gv0 = vmctx
    gv1 = load.i64 notrap aligned gv0+400000
    stack_limit = gv1
    ss0 = explicit_slot 20
block0(v0: i64):
    return
}

; VCode:
;   stp fp, lr, [sp, #-16]!
;   mov fp, sp
;   movz w16, #6784 ; movk w16, w16, #6, LSL #16 ; ldr x16, [x0, x16, SXTX]
;   add x16, x16, #32
;   subs xzr, sp, x16, UXTX
;   b.hs 8 ; udf
;   sub sp, sp, #32
; block0:
;   add sp, sp, #32
;   ldp fp, lr, [sp], #16
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   stp x29, x30, [sp, #-0x10]!
;   mov x29, sp
;   mov w16, #0x1a80
;   movk w16, #6, lsl #16
;   ldr x16, [x0, x16, sxtx]
;   add x16, x16, #0x20
;   cmp sp, x16
;   b.hs #0x24
;   .byte 0x1f, 0xc1, 0x00, 0x00 ; trap: stk_ovf
;   sub sp, sp, #0x20
; block1: ; offset 0x28
;   add sp, sp, #0x20
;   ldp x29, x30, [sp], #0x10
;   ret

