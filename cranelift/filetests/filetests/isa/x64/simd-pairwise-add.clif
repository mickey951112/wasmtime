test compile precise-output
target x86_64

function %fn1(i8x16) -> i16x8 {
block0(v0: i8x16):
  v1 = swiden_low v0
  v2 = swiden_high v0
  v3 = iadd_pairwise v1, v2
  return v3
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm4
;   movdqu  const(0), %xmm0
;   movdqa  %xmm4, %xmm5
;   pmaddubsw %xmm0, %xmm5, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %fn2(i16x8) -> i32x4 {
block0(v0: i16x8):
  v1 = swiden_low v0
  v2 = swiden_high v0
  v3 = iadd_pairwise v1, v2
  return v3
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqu  const(0), %xmm2
;   pmaddwd %xmm0, %xmm2, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %fn3(i8x16) -> i16x8 {
block0(v0: i8x16):
  v1 = uwiden_low v0
  v2 = uwiden_high v0
  v3 = iadd_pairwise v1, v2
  return v3
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqu  const(0), %xmm2
;   pmaddubsw %xmm0, %xmm2, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

function %fn4(i16x8) -> i32x4 {
block0(v0: i16x8):
  v1 = uwiden_low v0
  v2 = uwiden_high v0
  v3 = iadd_pairwise v1, v2
  return v3
}

;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqu  const(0), %xmm2
;   pxor    %xmm0, %xmm2, %xmm0
;   movdqu  const(1), %xmm6
;   pmaddwd %xmm0, %xmm6, %xmm0
;   movdqu  const(2), %xmm10
;   paddd   %xmm0, %xmm10, %xmm0
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret

