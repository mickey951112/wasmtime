test compile precise-output
target x86_64

function %one_arg(i32) system_v {
    ;; system_v has first param in %rdi, fascall in %rcx
    sig0 = (i32) windows_fastcall
block0(v0: i32):
    call_indirect sig0, v0(v0)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rdi, %rcx
;   subq    %rsp, $32, %rsp
;   virtual_sp_offset_adjust 32
;   call    *%rcx
;   addq    %rsp, $32, %rsp
;   virtual_sp_offset_adjust -32
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rcx
;   subq $0x20, %rsp
;   callq *%rcx
;   addq $0x20, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %two_args(i32, f32) system_v {
    ;; system_v has params in %rdi, %xmm0, fascall in %rcx, %xmm1
    sig0 = (i32, f32) windows_fastcall
    sig1 = (i32, f32) system_v
block0(v0: i32, v1: f32):
    call_indirect sig0, v0(v0, v1)
    call_indirect sig1, v0(v0, v1)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movdqa  %xmm0, %xmm6
;   subq    %rsp, $32, %rsp
;   virtual_sp_offset_adjust 32
;   movq    %rdi, %rcx
;   movdqa  %xmm6, %xmm1
;   call    *%rdi
;   addq    %rsp, $32, %rsp
;   virtual_sp_offset_adjust -32
;   movdqa  %xmm6, %xmm0
;   call    *%rdi
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movdqa %xmm0, %xmm6
;   subq $0x20, %rsp
;   movq %rdi, %rcx
;   movdqa %xmm6, %xmm1
;   callq *%rdi
;   addq $0x20, %rsp
;   movdqa %xmm6, %xmm0
;   callq *%rdi
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %fastcall_to_systemv(i32) windows_fastcall {
    ;; fastcall preserves xmm6+, rbx, rbp, rdi, rsi, r12-r15
    ;; system_v preserves no xmm registers, rbx, rbp, r12-r15
    sig0 = () system_v
block0(v0: i32):
    call_indirect sig0, v0()
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $176, %rsp
;   movq    %rsi, 0(%rsp)
;   movq    %rdi, 8(%rsp)
;   movdqu  %xmm6, 16(%rsp)
;   movdqu  %xmm7, 32(%rsp)
;   movdqu  %xmm8, 48(%rsp)
;   movdqu  %xmm9, 64(%rsp)
;   movdqu  %xmm10, 80(%rsp)
;   movdqu  %xmm11, 96(%rsp)
;   movdqu  %xmm12, 112(%rsp)
;   movdqu  %xmm13, 128(%rsp)
;   movdqu  %xmm14, 144(%rsp)
;   movdqu  %xmm15, 160(%rsp)
; block0:
;   call    *%rcx
;   movq    0(%rsp), %rsi
;   movq    8(%rsp), %rdi
;   movdqu  16(%rsp), %xmm6
;   movdqu  32(%rsp), %xmm7
;   movdqu  48(%rsp), %xmm8
;   movdqu  64(%rsp), %xmm9
;   movdqu  80(%rsp), %xmm10
;   movdqu  96(%rsp), %xmm11
;   movdqu  112(%rsp), %xmm12
;   movdqu  128(%rsp), %xmm13
;   movdqu  144(%rsp), %xmm14
;   movdqu  160(%rsp), %xmm15
;   addq    %rsp, $176, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0xb0, %rsp
;   movq %rsi, (%rsp)
;   movq %rdi, 8(%rsp)
;   movdqu %xmm6, 0x10(%rsp)
;   movdqu %xmm7, 0x20(%rsp)
;   movdqu %xmm8, 0x30(%rsp)
;   movdqu %xmm9, 0x40(%rsp)
;   movdqu %xmm10, 0x50(%rsp)
;   movdqu %xmm11, 0x60(%rsp)
;   movdqu %xmm12, 0x70(%rsp)
;   movdqu %xmm13, 0x80(%rsp)
;   movdqu %xmm14, 0x90(%rsp)
;   movdqu %xmm15, 0xa0(%rsp)
; block1: ; offset 0x61
;   callq *%rcx
;   movq (%rsp), %rsi
;   movq 8(%rsp), %rdi
;   movdqu 0x10(%rsp), %xmm6
;   movdqu 0x20(%rsp), %xmm7
;   movdqu 0x30(%rsp), %xmm8
;   movdqu 0x40(%rsp), %xmm9
;   movdqu 0x50(%rsp), %xmm10
;   movdqu 0x60(%rsp), %xmm11
;   movdqu 0x70(%rsp), %xmm12
;   movdqu 0x80(%rsp), %xmm13
;   movdqu 0x90(%rsp), %xmm14
;   movdqu 0xa0(%rsp), %xmm15
;   addq $0xb0, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %many_args(
    ;; rdi, rsi, rdx, rcx, r8, r9,
    i64, i64, i64, i64, i64, i64,

    ;; xmm0-7
    f64, f64, f64, f64, f64, f64, f64, f64,

    ;; stack args
    i64, i32, f32, f64
) system_v {
    sig0 = (
      i64, i64, i64, i64, i64, i64, f64, f64, f64, f64, f64, f64, f64, f64, i64,
      i32, f32, f64
    ) windows_fastcall
block0(
      v0: i64, v1:i64, v2:i64, v3:i64,
      v4:i64, v5:i64,
      v6: f64, v7: f64, v8:f64, v9:f64, v10:f64, v11:f64, v12:f64, v13:f64,
      v14:i64, v15:i32, v16:f32, v17:f64
):
    call_indirect sig0, v0(
      v0, v1, v2, v3,
      v4, v5, v6, v7,
      v8, v9, v10, v11,
      v12, v13, v14, v15,
      v16, v17
    )
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rcx, %rax
;   movq    %rdx, %rcx
;   movq    %rsi, %rdx
;   movq    %rdi, %rsi
;   movq    %rax, %rdi
;   movq    16(%rbp), %r10
;   movq    24(%rbp), %r11
;   movss   32(%rbp), %xmm9
;   movsd   40(%rbp), %xmm8
;   subq    %rsp, $144, %rsp
;   virtual_sp_offset_adjust 144
;   movq    %r8, 32(%rsp)
;   movq    %r9, 40(%rsp)
;   movsd   %xmm0, 48(%rsp)
;   movsd   %xmm1, 56(%rsp)
;   movsd   %xmm2, 64(%rsp)
;   movsd   %xmm3, 72(%rsp)
;   movsd   %xmm4, 80(%rsp)
;   movsd   %xmm5, 88(%rsp)
;   movsd   %xmm6, 96(%rsp)
;   movsd   %xmm7, 104(%rsp)
;   movq    %r10, 112(%rsp)
;   movl    %r11d, 120(%rsp)
;   movss   %xmm9, 128(%rsp)
;   movsd   %xmm8, 136(%rsp)
;   movq    %rdi, %r9
;   movq    %rcx, %r8
;   movq    %rsi, %rcx
;   call    *%rcx
;   addq    %rsp, $144, %rsp
;   virtual_sp_offset_adjust -144
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rcx, %rax
;   movq %rdx, %rcx
;   movq %rsi, %rdx
;   movq %rdi, %rsi
;   movq %rax, %rdi
;   movq 0x10(%rbp), %r10
;   movq 0x18(%rbp), %r11
;   movss 0x20(%rbp), %xmm9
;   movsd 0x28(%rbp), %xmm8
;   subq $0x90, %rsp
;   movq %r8, 0x20(%rsp)
;   movq %r9, 0x28(%rsp)
;   movsd %xmm0, 0x30(%rsp)
;   movsd %xmm1, 0x38(%rsp)
;   movsd %xmm2, 0x40(%rsp)
;   movsd %xmm3, 0x48(%rsp)
;   movsd %xmm4, 0x50(%rsp)
;   movsd %xmm5, 0x58(%rsp)
;   movsd %xmm6, 0x60(%rsp)
;   movsd %xmm7, 0x68(%rsp)
;   movq %r10, 0x70(%rsp)
;   movl %r11d, 0x78(%rsp)
;   movss %xmm9, 0x80(%rsp)
;   movsd %xmm8, 0x88(%rsp)
;   movq %rdi, %r9
;   movq %rcx, %r8
;   movq %rsi, %rcx
;   callq *%rcx
;   addq $0x90, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %many_ints(i64, i64, i64, i64, i64) system_v {
    ;; rdi => rcx
    ;; rsi => rdx
    ;; rdx => r8
    ;; rcx => r9
    ;; r8 => stack
    sig0 = (i64, i64, i64, i64, i64) windows_fastcall
block0(v0: i64, v1:i64, v2:i64, v3:i64, v4:i64):
    call_indirect sig0, v0(v0, v1, v2, v3, v4)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rdx, %r11
;   movq    %rcx, %r9
;   movq    %rsi, %rdx
;   movq    %rdi, %rcx
;   subq    %rsp, $48, %rsp
;   virtual_sp_offset_adjust 48
;   movq    %r8, 32(%rsp)
;   movq    %r11, %r8
;   call    *%rcx
;   addq    %rsp, $48, %rsp
;   virtual_sp_offset_adjust -48
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdx, %r11
;   movq %rcx, %r9
;   movq %rsi, %rdx
;   movq %rdi, %rcx
;   subq $0x30, %rsp
;   movq %r8, 0x20(%rsp)
;   movq %r11, %r8
;   callq *%rcx
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %many_args2(i32, f32, i64, f64, i32, i32, i32, f32, f64, f32, f64) system_v {
    sig0 = (i32, f32, i64, f64, i32, i32, i32, f32, f64, f32, f64) windows_fastcall
block0(v0: i32, v1: f32, v2: i64, v3: f64, v4: i32, v5: i32, v6: i32, v7: f32, v8: f64, v9: f32, v10: f64):
    call_indirect sig0, v0(v0, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rsi, %r9
;   movq    %rdi, %rsi
;   movdqa  %xmm1, %xmm12
;   movdqa  %xmm0, %xmm1
;   subq    %rsp, $96, %rsp
;   virtual_sp_offset_adjust 96
;   movl    %edx, 32(%rsp)
;   movl    %ecx, 40(%rsp)
;   movl    %r8d, 48(%rsp)
;   movss   %xmm2, 56(%rsp)
;   movsd   %xmm3, 64(%rsp)
;   movss   %xmm4, 72(%rsp)
;   movsd   %xmm5, 80(%rsp)
;   movq    %rsi, %rcx
;   movq    %r9, %r8
;   movdqa  %xmm12, %xmm3
;   call    *%rcx
;   addq    %rsp, $96, %rsp
;   virtual_sp_offset_adjust -96
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rsi, %r9
;   movq %rdi, %rsi
;   movdqa %xmm1, %xmm12
;   movdqa %xmm0, %xmm1
;   subq $0x60, %rsp
;   movl %edx, 0x20(%rsp)
;   movl %ecx, 0x28(%rsp)
;   movl %r8d, 0x30(%rsp)
;   movss %xmm2, 0x38(%rsp)
;   movsd %xmm3, 0x40(%rsp)
;   movss %xmm4, 0x48(%rsp)
;   movsd %xmm5, 0x50(%rsp)
;   movq %rsi, %rcx
;   movq %r9, %r8
;   movdqa %xmm12, %xmm3
;   callq *%rcx
;   addq $0x60, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix1(i32) wasmtime_system_v {
    sig0 = (i32) system_v
block0(v0: i32):
    call_indirect sig0, v0(v0)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   call    *%rdi
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   callq *%rdi
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix2(i32) system_v {
    sig0 = (i32) wasmtime_system_v
block0(v0: i32):
    call_indirect sig0, v0(v0)
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   call    *%rdi
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   callq *%rdi
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix2() -> i32, i32 system_v {
    sig0 = () -> i32, i32 wasmtime_system_v
block0:
    v2 = iconst.i32 1
    v0, v1 = call_indirect sig0, v2()
    return v0, v1
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movl    $1, %ecx
;   subq    %rsp, $16, %rsp
;   virtual_sp_offset_adjust 16
;   lea     0(%rsp), %rdi
;   call    *%rcx
;   movq    0(%rsp), %rdx
;   addq    %rsp, $16, %rsp
;   virtual_sp_offset_adjust -16
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movl $1, %ecx
;   subq $0x10, %rsp
;   leaq (%rsp), %rdi
;   callq *%rcx
;   movq (%rsp), %rdx
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix3() -> i32, i32 wasmtime_system_v {
    sig0 = () -> i32, i32 system_v
block0:
    v2 = iconst.i32 1
    v0, v1 = call_indirect sig0, v2()
    return v0, v1
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $16, %rsp
;   movq    %rbx, 0(%rsp)
; block0:
;   movq    %rdi, %rbx
;   movl    $1, %edx
;   call    *%rdx
;   movq    %rbx, %rdi
;   movl    %edx, 0(%rdi)
;   movq    0(%rsp), %rbx
;   addq    %rsp, $16, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
;   movq %rbx, (%rsp)
; block1: ; offset 0xc
;   movq %rdi, %rbx
;   movl $1, %edx
;   callq *%rdx
;   movq %rbx, %rdi
;   movl %edx, (%rdi)
;   movq (%rsp), %rbx
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix4() -> i32, i64, i32 wasmtime_system_v {
    sig0 = () -> i32, i64, i32 system_v
block0:
    v3 = iconst.i32 1
    v0, v1, v2 = call_indirect sig0, v3()
    return v0, v1, v2
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $16, %rsp
;   movq    %r13, 0(%rsp)
; block0:
;   movq    %rdi, %r13
;   movl    $1, %r9d
;   subq    %rsp, $16, %rsp
;   virtual_sp_offset_adjust 16
;   lea     0(%rsp), %rdi
;   call    *%r9
;   movq    0(%rsp), %rsi
;   addq    %rsp, $16, %rsp
;   virtual_sp_offset_adjust -16
;   movq    %r13, %rdi
;   movq    %rdx, 0(%rdi)
;   movl    %esi, 8(%rdi)
;   movq    0(%rsp), %r13
;   addq    %rsp, $16, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
;   movq %r13, (%rsp)
; block1: ; offset 0xc
;   movq %rdi, %r13
;   movl $1, %r9d
;   subq $0x10, %rsp
;   leaq (%rsp), %rdi
;   callq *%r9
;   movq (%rsp), %rsi
;   addq $0x10, %rsp
;   movq %r13, %rdi
;   movq %rdx, (%rdi)
;   movl %esi, 8(%rdi)
;   movq (%rsp), %r13
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix5() -> f32, i64, i32, f32 wasmtime_system_v {
    sig0 = () -> f32, i64, i32, f32 system_v
block0:
    v5 = iconst.i32 1
    v0, v1, v2, v3 = call_indirect sig0, v5()
    return v0, v1, v2, v3
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $16, %rsp
;   movq    %r13, 0(%rsp)
; block0:
;   movq    %rdi, %r13
;   movl    $1, %r9d
;   call    *%r9
;   movq    %r13, %rdi
;   movq    %rax, 0(%rdi)
;   movl    %edx, 8(%rdi)
;   movss   %xmm1, 12(%rdi)
;   movq    0(%rsp), %r13
;   addq    %rsp, $16, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
;   movq %r13, (%rsp)
; block1: ; offset 0xc
;   movq %rdi, %r13
;   movl $1, %r9d
;   callq *%r9
;   movq %r13, %rdi
;   movq %rax, (%rdi)
;   movl %edx, 8(%rdi)
;   movss %xmm1, 0xc(%rdi)
;   movq (%rsp), %r13
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %wasmtime_mix6(f32, i64, i32, f32) -> f32, i64, i32, f32 wasmtime_system_v {
    sig0 = (f32, i64, i32, f32) -> f32, i64, i32, f32 system_v
block0(v0: f32, v1: i64, v2: i32, v3: f32):
    v4 = iconst.i32 1
    v5, v6, v7, v8 = call_indirect sig0, v4(v0, v1, v2, v3)
    return v5, v6, v7, v8
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $16, %rsp
;   movq    %r12, 0(%rsp)
; block0:
;   movq    %rdx, %r12
;   movl    $1, %eax
;   call    *%rax
;   movq    %r12, %r8
;   movq    %rax, 0(%r8)
;   movl    %edx, 8(%r8)
;   movss   %xmm1, 12(%r8)
;   movq    0(%rsp), %r12
;   addq    %rsp, $16, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
;   movq %r12, (%rsp)
; block1: ; offset 0xc
;   movq %rdx, %r12
;   movl $1, %eax
;   callq *%rax
;   movq %r12, %r8
;   movq %rax, (%r8)
;   movl %edx, 8(%r8)
;   movss %xmm1, 0xc(%r8)
;   movq (%rsp), %r12
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

